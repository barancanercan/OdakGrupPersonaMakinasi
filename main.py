import asyncio
import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Optional
import pandas as pd
from dataclasses import dataclass, asdict
import google.generativeai as genai
from dotenv import load_dotenv
import re
import time
import base64

# Streamlit import - deployment iÃ§in
try:
    import streamlit as st
except ImportError:
    st = None

# CAMEL imports - deployment iÃ§in kontrol
try:
    from camel.agents import ChatAgent
    from camel.messages import BaseMessage
    from camel.types import RoleType
    CAMEL_AVAILABLE = True
except ImportError:
    CAMEL_AVAILABLE = False
    logging.warning("CAMEL-AI not available. Some features may be limited.")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

mcp_logs = []

def get_api_key():
    """API anahtarÄ±nÄ± gÃ¼venli ÅŸekilde al"""
    # Streamlit secrets Ã¶ncelikli
    if st and hasattr(st, 'secrets') and 'GEMINI_API_KEY' in st.secrets:
        return st.secrets['GEMINI_API_KEY']
    # Environment variable fallback
    return os.getenv('GEMINI_API_KEY')

def get_api_key_2():
    """Ä°kinci API anahtarÄ±nÄ± gÃ¼venli ÅŸekilde al"""
    if st and hasattr(st, 'secrets') and 'GEMINI_API_KEY_2' in st.secrets:
        return st.secrets['GEMINI_API_KEY_2']
    return os.getenv('GEMINI_API_KEY_2')

def check_required_files():
    """Deployment iÃ§in gerekli dosyalarÄ± kontrol et"""
    required_files = [
        'personas/elif.json',
        'personas/hatice_teyze.json',
        'personas/kenan_bey.json',
        'personas/tugrul_bey.json'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        logger.error(f"Eksik dosyalar: {missing_files}")
        if st:
            st.error(f"âŒ Eksik dosyalar: {missing_files}")
            st.info("ğŸ“ LÃ¼tfen ÅŸu klasÃ¶rlerin var olduÄŸundan emin olun: personas/, personas_pp/")
            st.stop()
        return False
    return True

@dataclass
class Persona:
    name: str
    bio: list
    lore: list
    knowledge: list
    topics: list
    style: dict
    adjectives: list
    modelProvider: str = None
    clients: list = None
    profile_pic: str = None
    role: str = None
    personality: str = None

    @classmethod
    def from_json(cls, json_file: str):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except FileNotFoundError:
            logger.error(f"Persona dosyasÄ± bulunamadÄ±: {json_file}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"JSON parse hatasÄ± {json_file}: {e}")
            raise
            
        name = data.get('name')
        if not name:
            raise ValueError(f"Persona adÄ± eksik: {json_file}")
            
        # Profil fotoÄŸrafÄ± dosya adÄ±nÄ± oluÅŸtur
        safe_name = re.sub(r'[^a-zA-Z0-9_]', '_', name.lower().replace(' ', '_'))
        
        # TÃ¼rkÃ§e karakter dÃ¶nÃ¼ÅŸÃ¼mÃ¼
        char_map = {'Ã§':'c', 'ÄŸ':'g', 'Ä±':'i', 'Ã¶':'o', 'ÅŸ':'s', 'Ã¼':'u'}
        ascii_name = safe_name
        for tr_char, en_char in char_map.items():
            ascii_name = ascii_name.replace(tr_char, en_char)
        
        base_path = 'personas_pp/'
        profile_pic = None
        
        # Ã–nce orijinal isimle dene
        for ext in ['.jpg', '.png', '.jpeg']:
            pic_path = f"{base_path}{safe_name}{ext}"
            if os.path.exists(pic_path):
                profile_pic = pic_path
                break
        
        # Bulamazsa ASCII versiyonla dene
        if not profile_pic:
            for ext in ['.jpg', '.png', '.jpeg']:
                pic_path = f"{base_path}{ascii_name}{ext}"
                if os.path.exists(pic_path):
                    profile_pic = pic_path
                    break
        
        return cls(
            name=name,
            bio=data.get('bio', []),
            lore=data.get('lore', []),
            knowledge=data.get('knowledge', []),
            topics=data.get('topics', []),
            style=data.get('style', {}),
            adjectives=data.get('adjectives', []),
            modelProvider=data.get('modelProvider'),
            clients=data.get('clients'),
            profile_pic=profile_pic,
            role=data.get('role', 'KatÄ±lÄ±mcÄ±'),
            personality=data.get('personality', 'NÃ¶tr')
        )

@dataclass
class AgendaItem:
    type: str
    link: str
    title: str
    content: str
    comments: str
    score: float = 0.0

class LLMClient:
    def __init__(self):
        self.api_key = get_api_key()
        self.api_key_2 = get_api_key_2()
        
        if not self.api_key:
            error_msg = "ğŸ”‘ GEMINI_API_KEY bulunamadÄ±!"
            logger.error(error_msg)
            if st:
                st.error(error_msg)
                st.info("ğŸ“ API anahtarÄ±nÄ± Streamlit secrets veya .env dosyasÄ±nda tanÄ±mlayÄ±n")
            raise ValueError("API key not found")
            
        self.current_api_key = self.api_key
        self.last_switch_time = time.time()
        self.switch_interval = 30
        self.retry_delay = 15
        self.max_retries = 3
        self.request_count = 0
        self.last_request_time = time.time()
        self.min_request_interval = 4
        self.request_log = []

    def _switch_api_key(self):
        """API anahtarlarÄ± arasÄ±nda geÃ§iÅŸ yapar"""
        if not self.api_key_2:
            return
            
        current_time = time.time()
        if current_time - self.last_switch_time >= self.switch_interval:
            self.current_api_key = self.api_key_2 if self.current_api_key == self.api_key else self.api_key
            self.last_switch_time = current_time
            logger.info(f"API anahtarÄ± deÄŸiÅŸtirildi")
            self.request_count = 0

    def _log_request(self, success: bool, error: str = None):
        """Ä°stek loglarÄ±nÄ± tutar"""
        log_entry = {
            'timestamp': datetime.now(),
            'api_key': self.current_api_key[:10] + '...' if self.current_api_key else 'None',
            'request_count': self.request_count,
            'success': success,
            'error': error
        }
        self.request_log.append(log_entry)
        
        # Son 100 logu tut
        if len(self.request_log) > 100:
            self.request_log = self.request_log[-100:]

    async def call_llm(self, prompt: str, max_retries: int = 3) -> str:
        """Call the LLM with retry logic and API key switching"""
        if not self.current_api_key:
            return "API anahtarÄ± bulunamadÄ±."
            
        for attempt in range(max_retries):
            try:
                # Ä°stekler arasÄ± minimum sÃ¼re kontrolÃ¼
                current_time = time.time()
                time_since_last_request = current_time - self.last_request_time
                if time_since_last_request < self.min_request_interval:
                    wait_time = self.min_request_interval - time_since_last_request
                    logger.info(f"Ä°stekler arasÄ± bekleme: {wait_time:.1f} saniye")
                    await asyncio.sleep(wait_time)

                self._switch_api_key()
                self.request_count += 1
                self.last_request_time = time.time()
                
                logger.info(f"LLM isteÄŸi gÃ¶nderiliyor (Deneme {attempt + 1}/{max_retries}, Ä°stek #{self.request_count})")
                
                genai.configure(api_key=self.current_api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                
                response = await asyncio.to_thread(
                    model.generate_content,
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.7,
                        top_p=0.8,
                        top_k=40,
                        max_output_tokens=3072,
                    )
                )
                
                if response.text:
                    self._log_request(success=True)
                    return response.text
                else:
                    logger.warning("Empty response from LLM")
                    self._log_request(success=False, error="Empty response")
                    return "ÃœzgÃ¼nÃ¼m, ÅŸu anda yanÄ±t veremiyorum."
                    
            except Exception as e:
                error_msg = str(e)
                logger.error(f"LLM call failed: {error_msg}")
                self._log_request(success=False, error=error_msg)
                
                if "429" in error_msg or "quota" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = self.retry_delay * (attempt + 1)
                        logger.warning(f"Rate limit aÅŸÄ±ldÄ±. {wait_time} saniye bekleniyor...")
                        if st:
                            st.warning(f"â³ API kotasÄ± doldu, {wait_time} saniye bekleniyor...")
                        await asyncio.sleep(wait_time)
                        continue
                
                if "network" in error_msg.lower() or "connection" in error_msg.lower():
                    if st:
                        st.error("ğŸŒ Ä°nternet baÄŸlantÄ±sÄ± sorunu")
                
                if attempt == max_retries - 1:
                    if st:
                        st.error("âŒ LLM servisine ulaÅŸÄ±lamÄ±yor")
                    return "ÃœzgÃ¼nÃ¼m, ÅŸu anda yanÄ±t veremiyorum. LÃ¼tfen daha sonra tekrar deneyin."
                
                await asyncio.sleep(2 ** attempt)  # Exponential backoff

    def get_request_stats(self) -> dict:
        """Ä°stek istatistiklerini dÃ¶ndÃ¼rÃ¼r"""
        total_requests = len(self.request_log)
        successful_requests = sum(1 for log in self.request_log if log['success'])
        failed_requests = total_requests - successful_requests
        
        return {
            'total_requests': total_requests,
            'successful_requests': successful_requests,
            'failed_requests': failed_requests,
            'success_rate': (successful_requests / total_requests * 100) if total_requests > 0 else 0,
            'current_request_count': self.request_count,
            'last_request_time': self.last_request_time
        }

class MCPThinkingAgent:
    def __init__(self, llm_client: LLMClient, simulator=None):
        self.llm_client = llm_client
        self.simulator = simulator
    
    async def score_agenda_item(self, persona: Persona, item: AgendaItem) -> float:
        """Score an agenda item based on persona's perspective"""
        prompt = f"""[SÄ°STEM MESAJI]
Sen bir "Ä°Ã§erik Puanlama UzmanÄ±"sÄ±n. Sana bir persona profili ve bir gÃ¼ndem maddesi verilecektir. Bu persona rolÃ¼ne bÃ¼rÃ¼nerek, gÃ¼ndem maddesine 1'den 10'a kadar bir "ilgi ve hatÄ±rlama" puanÄ± ver.

[PERSONA PROFÄ°LÄ°]
Ä°sim: {persona.name}
Rol: {persona.role}
KiÅŸilik: {persona.personality}
Biyo: {persona.bio}
GeÃ§miÅŸ: {persona.lore}
Bilgi: {persona.knowledge}
Konular: {persona.topics}
Stil: {persona.style}
SÄ±fatlar: {persona.adjectives}

[GÃœNDEM MADDESÄ°]
BaÅŸlÄ±k: {item.title}
Ä°Ã§erik: {item.content}
Yorumlar: {item.comments}

[TALÄ°MATLAR]
1. YukarÄ±daki persona profilini ve gÃ¼ndem maddesini dikkatlice oku.
2. PersonanÄ±n rolÃ¼, kiÅŸiliÄŸi ve diÄŸer Ã¶zelliklerini referans alarak, bu gÃ¼ndem maddesinin persona iÃ§in ne kadar alakalÄ± ve Ã¶nemli olduÄŸunu deÄŸerlendir.
3. YanÄ±tÄ±n sadece 1 ile 10 arasÄ±nda bir sayÄ± olsun. BaÅŸka hiÃ§bir metin veya aÃ§Ä±klama ekleme.
"""
        
        response = await self.llm_client.call_llm(prompt)
        try:
            # Extract the first number from the response
            score_match = re.search(r'\d+', response)
            if score_match:
                score = float(score_match.group())
                return min(max(score, 1), 10)
            else:
                logger.warning(f"Score parsing failed for response: {response}")
                return 5.0
        except Exception as e:
            logger.error(f"Score parsing error: {e}")
            return 5.0
    
    async def validate_response(self, persona: Persona, context: str, response_draft: str) -> str:
        """Validate and improve persona response for consistency"""
        prompt = f"""[SÄ°STEM MESAJI]
Sen bir "Karakter TutarlÄ±lÄ±k KontrolÃ¶rÃ¼"sÃ¼n. Sana bir persona profili, mevcut tartÄ±ÅŸma baÄŸlamÄ± ve personanÄ±n olasÄ± bir yanÄ±t taslaÄŸÄ± verilecektir. Bu taslaÄŸÄ±n personanÄ±n karakterine, tarzÄ±na ve Ã¶nceki yorumlarÄ±na tam olarak uygun olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendir. GerektiÄŸinde taslaÄŸÄ± iyileÅŸtirerek daha tutarlÄ± bir yanÄ±t oluÅŸtur.

[PERSONA PROFÄ°LÄ°]
Ä°sim: {persona.name}
Biyo: {persona.bio}
GeÃ§miÅŸ: {persona.lore}
Bilgi: {persona.knowledge}
Konular: {persona.topics}
Stil: {persona.style}
SÄ±fatlar: {persona.adjectives}

[TARTIÅMA BAÄLAMI]
{context}

[PERSONANIN OlasÄ± YANITI (TASLAK)]
{response_draft}

[TALÄ°MATLAR]
1. PersonanÄ±n "bio", "lore", "knowledge", "topics", "style" ve "adjectives" alanlarÄ±nÄ± referans alarak, taslaÄŸÄ±n bu Ã¶zelliklere uygunluÄŸunu deÄŸerlendir.
2. Taslak, personanÄ±n mevcut bilgi birikimi veya gÃ¶rÃ¼ÅŸleriyle Ã§eliÅŸiyor mu?
3. Taslak, personanÄ±n tanÄ±mlanmÄ±ÅŸ konuÅŸma tarzÄ±na ("all", "chat", "post") ve sÄ±fatlarÄ±na uygun mu?
4. Taslak, tartÄ±ÅŸmanÄ±n genel akÄ±ÅŸÄ±na ve mantÄ±ÄŸÄ±na uygun mu?
5. EÄŸer taslak tutarlÄ± ve uygunsa, taslaÄŸÄ± olduÄŸu gibi tekrar et.
6. EÄŸer taslak tutarsÄ±zsa veya geliÅŸtirilmesi gerekiyorsa, personanÄ±n karakterine tam olarak uygun, mantÄ±klÄ± ve baÄŸlamla uyumlu yeni bir yanÄ±t oluÅŸtur. YanÄ±t, sadece personanÄ±n sÃ¶yleyeceÄŸi sÃ¶zler olmalÄ±dÄ±r, baÅŸka bir aÃ§Ä±klama veya ekleme yapma.
"""
        response = await self.llm_client.call_llm(prompt)
        log_entry = {"type": "validate", "prompt": prompt, "response": response}
        mcp_logs.append(log_entry)
        if self.simulator is not None and hasattr(self.simulator, 'mcp_logs'):
            self.simulator.mcp_logs.append(log_entry)
        return response.strip()

    async def summarize_for_persona(self, persona, agenda_item, score):
        prompt = f"""[SÄ°STEM MESAJI]
Sen bir \"HatÄ±rlama UzmanÄ±\"sÄ±n. Sana bir persona profili, bir haber ve bu personanÄ±n haberi okuma dikkat seviyesi (1-10) verilecek. LÃ¼tfen, bu persona bu haberi bu dikkat seviyesiyle okusa, neleri hatÄ±rlar, neleri unutur, hangi ana fikri aklÄ±nda tutar, Ã¶zetle. YanÄ±tÄ±n sadece persona'nÄ±n aklÄ±nda kalanlar olsun.

[PERSONA PROFÄ°LÄ°]
Ä°sim: {persona.name}
Biyo: {persona.bio}
GeÃ§miÅŸ: {persona.lore}
Bilgi: {persona.knowledge}
Konular: {persona.topics}
Stil: {persona.style}
SÄ±fatlar: {persona.adjectives}

[GÃœNDEM MADDESÄ°]
BaÅŸlÄ±k: {agenda_item.title}
Ä°Ã§erik: {agenda_item.content}
Yorumlar: {agenda_item.comments}

[DÄ°KKAT SEVÄ°YESÄ°]: {score}

[TALÄ°MATLAR]
- Dikkat seviyesi dÃ¼ÅŸÃ¼kse, Ã¶nemli detaylarÄ± atla veya unut.
- Dikkat seviyesi ortaysa, ana fikri ve bazÄ± detaylarÄ± hatÄ±rla.
- Dikkat seviyesi yÃ¼ksekse, Ã§oÄŸu detayÄ± ve ana fikri hatÄ±rla.
- YanÄ±tÄ±n sadece persona'nÄ±n aklÄ±nda kalanlar olsun, baÅŸka aÃ§Ä±klama ekleme.
"""
        response = await self.llm_client.call_llm(prompt)
        log_entry = {"type": "memory", "prompt": prompt, "response": response}
        mcp_logs.append(log_entry)
        if self.simulator is not None and hasattr(self.simulator, 'mcp_logs'):
            self.simulator.mcp_logs.append(log_entry)
        return response.strip()

# CAMEL-AI kullanÄ±lamÄ±yorsa basit bir agent sÄ±nÄ±fÄ±
class SimpleChatAgent:
    def __init__(self, system_message):
        self.system_message = system_message

class FocusGroupAgent:
    def __init__(self, persona: Persona, llm_client: LLMClient, mcp_agent: MCPThinkingAgent):
        self.persona = persona
        self.llm_client = llm_client
        self.mcp_agent = mcp_agent
        self.conversation_history = []
        
        # Create system message for persona
        self.system_message = self._create_system_message()
        
        # CAMEL-AI varsa kullan, yoksa basit versiyona geÃ§
        if CAMEL_AVAILABLE:
            try:
                from camel.agents import ChatAgent
                from camel.messages import BaseMessage
                # CAMEL agent'Ä± baÅŸlatmaya Ã§alÄ±ÅŸ
                pass
            except Exception as e:
                logger.warning(f"CAMEL agent baÅŸlatÄ±lamadÄ±: {e}")
    
    def _create_system_message(self) -> str:
        content = f"""[SÄ°STEM MESAJI]
Sen {self.persona.name} adlÄ± personasÄ±n. Sana ait tÃ¼m kiÅŸisel bilgiler, geÃ§miÅŸ, bilgi alanlarÄ±, konuÅŸma tarzÄ± ve sÄ±fatlar aÅŸaÄŸÄ±da verilmiÅŸtir. Odak grup tartÄ±ÅŸmasÄ±nda, bu karakterine tamamen uygun bir ÅŸekilde hareket etmeli ve konuÅŸmalÄ±sÄ±n.

[PERSONA PROFÄ°LÄ°]
Ä°sim: {self.persona.name}
Biyo: {self.persona.bio}
GeÃ§miÅŸ: {self.persona.lore}
Bilgi: {self.persona.knowledge}
Konular: {self.persona.topics}
Stil: {self.persona.style}
SÄ±fatlar: {self.persona.adjectives}

[TALÄ°MATLAR]
1. "bio", "lore", "knowledge", "topics", "style" ve "adjectives" alanlarÄ±nÄ± her yanÄ±tÄ±nda iÃ§selleÅŸtir.
2. YanÄ±tlarÄ±n, personanÄ±n yaÅŸÄ±ndan, eÄŸitiminden, sosyo-ekonomik durumundan ve inanÃ§larÄ±ndan etkilenmiÅŸ olmalÄ±dÄ±r.
3. "style" (all, chat, post) ve "adjectives" (Ã¶rneÄŸin "Teknolojiden bi haber", "Saf ve cahil", "Kolay KandÄ±rÄ±labilir") Ã¶zelliklerini konuÅŸma tarzÄ±na ve kelime seÃ§imine yansÄ±t.
4. GÃ¼ndem maddesine ve diÄŸer personalarÄ±n yorumlarÄ±na, kendi personanÄ±n bakÄ±ÅŸ aÃ§Ä±sÄ±yla tepki ver.
5. YanÄ±tlarÄ±n doÄŸal ve gerÃ§ekÃ§i olmalÄ±, yapay zeka tarafÄ±ndan Ã¼retildiÄŸi anlaÅŸÄ±lmamalÄ±dÄ±r.
6. Sadece personanÄ±n sÃ¶yleyeceÄŸi sÃ¶zleri yaz. AÃ§Ä±klama veya meta-yorum yapma.
"""
        return content
    
    async def generate_response(self, context: str, agenda_item: AgendaItem) -> str:
        """Generate persona response with MCP validation"""
        # Persona'nÄ±n bu haber iÃ§in belleÄŸindeki Ã¶zeti kullan
        try:
            from main import simulator
            memory_key = (self.persona.name, agenda_item.title)
            memory_summary = simulator.memory.get(memory_key, None)
        except:
            memory_summary = None
            
        if memory_summary:
            prompt = f"""{self.system_message}

[TARTIÅMA BAÄLAMI]
{context}
Åu anki gÃ¼ndem maddesi (senin hatÄ±rladÄ±ÄŸÄ±n kadarÄ±yla): {memory_summary}

[TALÄ°MATLAR]
1. "bio", "lore", "knowledge", "topics", "style" ve "adjectives" alanlarÄ±nÄ± her yanÄ±tÄ±nda iÃ§selleÅŸtir.
2. YanÄ±tlarÄ±n, personanÄ±n yaÅŸÄ±ndan, eÄŸitiminden, sosyo-ekonomik durumundan ve inanÃ§larÄ±ndan etkilenmiÅŸ olmalÄ±dÄ±r.
3. "style" (all, chat, post) ve "adjectives" (Ã¶rneÄŸin "Teknolojiden bi haber", "Saf ve cahil", "Kolay KandÄ±rÄ±labilir") Ã¶zelliklerini konuÅŸma tarzÄ±na ve kelime seÃ§imine yansÄ±t.
4. GÃ¼ndem maddesine ve diÄŸer personalarÄ±n yorumlarÄ±na, kendi personanÄ±n bakÄ±ÅŸ aÃ§Ä±sÄ±yla tepki ver.
5. DiÄŸer personalarÄ± ikna etmeye Ã§alÄ±ÅŸ. Fikir ayrÄ±lÄ±ÄŸÄ± olduÄŸunda karÅŸÄ± Ã§Ä±k, gerekirse duygusal tepki ver, kÄ±z, yÃ¼ksel. TartÄ±ÅŸmacÄ± ve canlÄ± bir Ã¼slup kullan.
6. YanÄ±tlarÄ±n doÄŸal ve gerÃ§ekÃ§i olmalÄ±, yapay zeka tarafÄ±ndan Ã¼retildiÄŸi anlaÅŸÄ±lmamalÄ±dÄ±r.
7. Sadece personanÄ±n sÃ¶yleyeceÄŸi sÃ¶zleri yaz. AÃ§Ä±klama veya meta-yorum yapma.
"""
        else:
            # Bellek yoksa eski davranÄ±ÅŸ
            prompt = f"""{self.system_message}

[TARTIÅMA BAÄLAMI]
{context}
Åu anki gÃ¼ndem maddesi: {agenda_item.title} - {agenda_item.content}
"""
        
        response = await self.llm_client.call_llm(prompt)
        return response.strip()

class ModeratorAgent:
    def __init__(self, llm_client: LLMClient):
        self.llm_client = llm_client
        self.conversation_history = []
    
    async def start_discussion(self, agenda_item: AgendaItem, first_persona: str) -> str:
        """Start the discussion"""
        prompt = f"""[SÄ°STEM MESAJI]
Sen bir "Odak Grup ModeratÃ¶rÃ¼"sÃ¼n. AmacÄ±n, sana verilen gÃ¼ndem maddesi etrafÄ±nda personalar arasÄ±nda verimli ve adil bir tartÄ±ÅŸma ortamÄ± saÄŸlamaktÄ±r. TarafsÄ±z kalmalÄ±, tÃ¼m personalara eÅŸit sÃ¶z hakkÄ± tanÄ±malÄ± ve tartÄ±ÅŸmanÄ±n belirlenen gÃ¼ndemden sapmamasÄ±nÄ± saÄŸlamalÄ±sÄ±n.

[GÃœNDEM MADDESÄ°]
BaÅŸlÄ±k: {agenda_item.title}
Ä°Ã§erik: {agenda_item.content}

TartÄ±ÅŸmayÄ± "Merhaba, bugÃ¼n [{agenda_item.title}] konusunu konuÅŸmak Ã¼zere toplandÄ±k. Bu konuda ilk sÃ¶zÃ¼ {first_persona}'ya vermek istiyorum." gibi bir cÃ¼mleyle baÅŸlat.
"""
        
        response = await self.llm_client.call_llm(prompt)
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'speaker': 'ModeratÃ¶r',
            'message': response
        })
        return response
    
    async def give_turn(self, previous_persona: str, next_persona: str) -> str:
        """Give turn to next persona"""
        prompt = f"""Sen moderatÃ¶rsÃ¼n. {previous_persona} konuÅŸtu, ÅŸimdi sÄ±rayÄ± {next_persona}'ya ver. KÄ±sa ve Ã¶z bir geÃ§iÅŸ cÃ¼mlesi sÃ¶yle."""
        
        response = await self.llm_client.call_llm(prompt)
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'speaker': 'ModeratÃ¶r',
            'message': response
        })
        return response

class OverseerAgent:
    def __init__(self, llm_client: LLMClient):
        self.llm_client = llm_client
    
    async def analyze_discussion(self, full_discussion: str) -> str:
        """Analyze the complete discussion"""
        prompt = f"""[SÄ°STEM MESAJI]
Sen bir "Siyaset ve Sosyoloji UzmanÄ±"sÄ±n. Sana bir odak grup tartÄ±ÅŸmasÄ±nÄ±n tam metni verilecektir. Bu metni derinlemesine analiz et ve aÅŸaÄŸÄ±daki kriterlere gÃ¶re kapsamlÄ± bir rapor oluÅŸtur.

[ODAK GRUP TARTIÅMA METNÄ°]
{full_discussion}

[RAPOR TALÄ°MATLARI]
AÅŸaÄŸÄ±daki baÅŸlÄ±klarÄ± kullanarak detaylÄ± bir rapor hazÄ±rla:

1. **GiriÅŸ:** TartÄ±ÅŸmanÄ±n konusu ve katÄ±lÄ±mcÄ±larÄ±n (personalarÄ±n) kÄ±sa tanÄ±tÄ±mÄ±.
2. **Ana TartÄ±ÅŸma NoktalarÄ± ve Temalar:** TartÄ±ÅŸmada Ã¶ne Ã§Ä±kan ana konular, alt baÅŸlÄ±klar ve tekrar eden temalar nelerdi?
3. **Persona BazlÄ± KatkÄ±lar ve BakÄ±ÅŸ AÃ§Ä±larÄ±:**
   * Her bir personanÄ±n tartÄ±ÅŸmaya nasÄ±l bir katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± ve hangi bakÄ±ÅŸ aÃ§Ä±larÄ±nÄ± temsil ettiÄŸini detaylandÄ±r.
   * PersonalarÄ±n kendi karakter Ã¶zellikleriyle ne kadar tutarlÄ± davrandÄ±ÄŸÄ±nÄ± deÄŸerlendir.
4. **Ä°nteraksiyon Analizi:**
   * Personalar arasÄ±nda belirgin anlaÅŸmazlÄ±k veya fikir birliÄŸi noktalarÄ± nelerdi?
   * Hangi personalar birbirini destekledi, hangileri karÅŸÄ± Ã§Ä±ktÄ±? Neden?
   * ModeratÃ¶rÃ¼n rolÃ¼ tartÄ±ÅŸmayÄ± nasÄ±l etkiledi?
5. **Sosyolojik ve Politik Analizler:**
   * TartÄ±ÅŸmada gÃ¶zlemlenen sosyal veya kÃ¼ltÃ¼rel eÄŸilimler nelerdir?
   * KatÄ±lÄ±mcÄ±larÄ±n politik gÃ¶rÃ¼ÅŸleri ve bu gÃ¶rÃ¼ÅŸlerin tartÄ±ÅŸmaya yansÄ±malarÄ± nasÄ±l oldu?
   * Ortaya Ã§Ä±kan genel kamuoyu eÄŸilimleri veya toplumsal hassasiyetler var mÄ±ydÄ±?
6. **Beklenmedik Bulgular / AykÄ±rÄ± GÃ¶rÃ¼ÅŸler:** Beklenenin dÄ±ÅŸÄ±nda ortaya Ã§Ä±kan yorumlar veya bakÄ±ÅŸ aÃ§Ä±larÄ± oldu mu?
7. **SonuÃ§ ve Ã–neriler:** TartÄ±ÅŸmanÄ±n genel Ã¶zeti ve elde edilen ana bulgular. Gelecekteki araÅŸtÄ±rmalar veya politika belirleme iÃ§in olasÄ± Ã§Ä±karÄ±mlar ve Ã¶neriler.

Raporunu akademik ve objektif bir dille yaz. Analizlerini somut Ã¶rneklerle destekle.
"""
        
        analysis = await self.llm_client.call_llm(prompt)
        return analysis

class FocusGroupSimulator:
    def __init__(self):
        try:
            self.llm_client = LLMClient()
            self.mcp_agent = MCPThinkingAgent(self.llm_client, self)
            self.moderator = ModeratorAgent(self.llm_client)
            self.overseer = OverseerAgent(self.llm_client)
            
            self.personas: List[Persona] = []
            self.agents: List[FocusGroupAgent] = []
            self.agenda_items: List[AgendaItem] = []
            self.discussion_log = []
            self.is_running = False
            self.memory = {}
            self.mcp_logs = []
            
            # Create necessary directories
            os.makedirs("personas", exist_ok=True)
            os.makedirs("personas_pp", exist_ok=True)
            os.makedirs("data", exist_ok=True)
            
            # Load personas if files exist
            self.load_personas()
            
        except Exception as e:
            logger.error(f"Simulator initialization failed: {e}")
            if st:
                st.error(f"âŒ Simulator baÅŸlatÄ±lamadÄ±: {e}")
            raise
    
    def load_personas(self):
        """Load personas from JSON files"""
        persona_files = [
            'personas/elif.json',
            'personas/hatice_teyze.json',
            'personas/kenan_bey.json',
            'personas/tugrul_bey.json'
        ]
        
        loaded_count = 0
        for file_path in persona_files:
            if os.path.exists(file_path):
                try:
                    persona = Persona.from_json(file_path)
                    self.personas.append(persona)
                    agent = FocusGroupAgent(persona, self.llm_client, self.mcp_agent)
                    self.agents.append(agent)
                    loaded_count += 1
                    logger.info(f"Loaded persona: {persona.name}")
                except Exception as e:
                    logger.error(f"Failed to load persona from {file_path}: {e}")
                    if st:
                        st.warning(f"âš ï¸ {file_path} yÃ¼klenemedi: {e}")
            else:
                logger.warning(f"Persona dosyasÄ± bulunamadÄ±: {file_path}")
                
        if loaded_count == 0:
            logger.warning("HiÃ§ persona yÃ¼klenemedi!")
            if st:
                st.warning("âš ï¸ HiÃ§ persona dosyasÄ± bulunamadÄ±. personas/ klasÃ¶rÃ¼nÃ¼ kontrol edin.")
        else:
            logger.info(f"{loaded_count} persona baÅŸarÄ±yla yÃ¼klendi")
    
    def load_agenda_data(self, file_path: str):
        """Load agenda data from CSV/Excel with improved error handling"""
        try:
            # Dosya var mÄ± kontrol et
            if not os.path.exists(file_path):
                logger.error(f"File not found: {file_path}")
                if st:
                    st.error(f"ğŸ“ Dosya bulunamadÄ±: {file_path}")
                return False

            # Dosya formatÄ±nÄ± kontrol et ve oku
            file_extension = os.path.splitext(file_path)[1].lower()
            
            if file_extension == '.csv':
                try:
                    df = pd.read_csv(file_path, encoding='utf-8')
                except UnicodeDecodeError:
                    try:
                        df = pd.read_csv(file_path, encoding='latin-1')
                    except:
                        df = pd.read_csv(file_path, encoding='cp1254')
            elif file_extension in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path)
            else:
                logger.error(f"Unsupported file format: {file_extension}")
                if st:
                    st.error(f"âŒ Desteklenmeyen dosya formatÄ±: {file_extension}")
                return False

            if df.empty:
                logger.error("File is empty")
                if st:
                    st.error("ğŸ“„ Dosya boÅŸ!")
                return False

            # SÃ¼tun adlarÄ±nÄ± temizle (boÅŸluklarÄ± kaldÄ±r)
            df.columns = df.columns.str.strip()
            
            # Gerekli sÃ¼tunlarÄ± kontrol et (bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z)
            required_columns = ['TYPE', 'LINK', 'TITLE', 'CONTENT', 'COMMENTS']
            df_columns_upper = [col.upper() for col in df.columns]
            
            missing_columns = []
            column_mapping = {}
            
            for req_col in required_columns:
                found = False
                for i, df_col in enumerate(df_columns_upper):
                    if req_col == df_col:
                        column_mapping[req_col] = df.columns[i]
                        found = True
                        break
                if not found:
                    missing_columns.append(req_col)
            
            if missing_columns:
                logger.error(f"Missing required columns: {missing_columns}")
                if st:
                    st.error(f"âŒ Eksik sÃ¼tunlar: {missing_columns}")
                    st.info(f"ğŸ“‹ Mevcut sÃ¼tunlar: {list(df.columns)}")
                    st.info(f"ğŸ” Gerekli sÃ¼tunlar: {required_columns}")
                return False

            # Verileri yÃ¼kle
            self.agenda_items = []
            loaded_items = 0
            
            for index, row in df.iterrows():
                try:
                    # BoÅŸ satÄ±rlarÄ± atla
                    if pd.isna(row[column_mapping['TITLE']]) or str(row[column_mapping['TITLE']]).strip() == '':
                        continue
                        
                    item = AgendaItem(
                        type=str(row.get(column_mapping['TYPE'], '')),
                        link=str(row.get(column_mapping['LINK'], '')),
                        title=str(row.get(column_mapping['TITLE'], '')),
                        content=str(row.get(column_mapping['CONTENT'], '')),
                        comments=str(row.get(column_mapping['COMMENTS'], ''))
                    )
                    self.agenda_items.append(item)
                    loaded_items += 1
                except Exception as e:
                    logger.warning(f"SatÄ±r {index + 1} atlandÄ±: {e}")
                    continue

            if loaded_items == 0:
                logger.error("No valid agenda items found")
                if st:
                    st.error("ğŸ“‹ GeÃ§erli gÃ¼ndem maddesi bulunamadÄ±!")
                return False

            logger.info(f"Successfully loaded {loaded_items} agenda items")
            if st:
                st.success(f"âœ… {loaded_items} gÃ¼ndem maddesi baÅŸarÄ±yla yÃ¼klendi!")
            return True

        except Exception as e:
            logger.error(f"Failed to load agenda data: {str(e)}")
            if st:
                st.error(f"âŒ GÃ¼ndem yÃ¼kleme hatasÄ±: {str(e)}")
            return False
    
    async def score_agenda_items(self):
        """Score all agenda items for all personas with progress tracking"""
        if not self.agenda_items or not self.personas:
            return
            
        total_operations = len(self.agenda_items) * len(self.personas)
        completed_operations = 0
        
        if st:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        for item in self.agenda_items:
            scores = []
            for persona in self.personas:
                try:
                    if st:
                        status_text.text(f"ğŸ¯ {persona.name} iÃ§in {item.title} puanlanÄ±yor...")
                    
                    score = await self.mcp_agent.score_agenda_item(persona, item)
                    scores.append(score)
                    
                    summary = await self.mcp_agent.summarize_for_persona(persona, item, score)
                    self.memory[(persona.name, item.title)] = summary
                    
                    completed_operations += 1
                    if st:
                        progress_bar.progress(completed_operations / total_operations)
                        
                except Exception as e:
                    logger.error(f"Error scoring {item.title} for {persona.name}: {e}")
                    scores.append(5.0)  # Default score
                    completed_operations += 1
                    if st:
                        progress_bar.progress(completed_operations / total_operations)
            
            item.score = sum(scores) / len(scores) if scores else 0.0
        
        if st:
            status_text.text("âœ… Puanlama tamamlandÄ±!")
            progress_bar.empty()
            status_text.empty()
    
    async def start_simulation(self, max_rounds=10):
        """Start the focus group simulation with improved error handling"""
        if not self.agenda_items:
            raise ValueError("GÃ¼ndem maddeleri yÃ¼klenmemiÅŸ!")
        
        if not self.personas:
            raise ValueError("HiÃ§ persona yÃ¼klenmemiÅŸ!")
            
        self.is_running = True
        self.discussion_log = []
        round_count = 0
        
        try:
            while self.is_running and round_count < max_rounds:
                for agenda_item in self.agenda_items:
                    if not self.is_running:
                        break
                    
                    # ModeratÃ¶r giriÅŸi
                    first_persona = self.personas[0].name if self.personas else "katÄ±lÄ±mcÄ±"
                    try:
                        moderator_intro = await self.moderator.start_discussion(agenda_item, first_persona)
                        self.discussion_log.append({
                            'timestamp': datetime.now(),
                            'speaker': 'ModeratÃ¶r',
                            'message': moderator_intro
                        })
                        await asyncio.sleep(2)
                    except Exception as e:
                        logger.error(f"Moderator intro failed: {e}")
                        continue
                    
                    # Her persona konuÅŸsun
                    for i, agent in enumerate(self.agents):
                        if not self.is_running:
                            break
                        
                        try:
                            context = self._build_context()
                            response = await agent.generate_response(context, agenda_item)
                            self.discussion_log.append({
                                'timestamp': datetime.now(),
                                'speaker': agent.persona.name,
                                'message': response
                            })
                            await asyncio.sleep(3)
                            
                            # ModeratÃ¶r sÄ±radaki kiÅŸiye sÃ¶z versin (sonuncu hariÃ§)
                            if i < len(self.agents) - 1:
                                next_persona = self.agents[i + 1].persona.name
                                moderator_transition = await self.moderator.give_turn(
                                    agent.persona.name, next_persona
                                )
                                self.discussion_log.append({
                                    'timestamp': datetime.now(),
                                    'speaker': 'ModeratÃ¶r',
                                    'message': moderator_transition
                                })
                                await asyncio.sleep(2)
                        except Exception as e:
                            logger.error(f"Agent response failed for {agent.persona.name}: {e}")
                            # Hata durumunda varsayÄ±lan yanÄ±t ekle
                            self.discussion_log.append({
                                'timestamp': datetime.now(),
                                'speaker': agent.persona.name,
                                'message': f"Ã–zÃ¼r dilerim, ÅŸu anda fikrimi ifade edemiyorum."
                            })
                
                round_count += 1
        except Exception as e:
            logger.error(f"Simulation error: {e}")
            self.is_running = False
            raise
        finally:
            self.is_running = False
        
        return self.discussion_log
    
    def _build_context(self) -> str:
        """Build conversation context from discussion log"""
        context_parts = []
        for entry in self.discussion_log[-5:]:  # Son 5 mesaj
            context_parts.append(f"{entry['speaker']}: {entry['message']}")
        return "\n".join(context_parts)
    
    def stop_simulation(self):
        """Stop the simulation"""
        self.is_running = False
        logger.info("Simulation stopped by user")
    
    async def generate_analysis(self) -> str:
        """Generate final analysis report"""
        if not self.discussion_log:
            return "Analiz edilecek tartÄ±ÅŸma bulunamadÄ±."
            
        full_discussion = self._build_full_discussion()
        if not full_discussion.strip():
            return "BoÅŸ tartÄ±ÅŸma - analiz edilecek iÃ§erik yok."
            
        try:
            analysis = await self.overseer.analyze_discussion(full_discussion)
            return analysis
        except Exception as e:
            logger.error(f"Analysis generation failed: {e}")
            return f"Analiz oluÅŸturulurken hata oluÅŸtu: {str(e)}"
    
    def _build_full_discussion(self) -> str:
        """Build complete discussion text"""
        discussion_parts = []
        for entry in self.discussion_log:
            timestamp = entry['timestamp'].strftime("%H:%M:%S")
            discussion_parts.append(f"[{timestamp}] {entry['speaker']}: {entry['message']}")
        return "\n".join(discussion_parts)

# Global simulator instance with error handling
try:
    simulator = FocusGroupSimulator()
    logger.info("Simulator initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize simulator: {e}")
    simulator = None

if __name__ == "__main__":
    print("main.py loaded successfully")
    print(f"Simulator available: {simulator is not None}")
    if simulator:
        print(f"Personas loaded: {len(simulator.personas)}")
    else:
        print("Simulator initialization failed - check API keys and dependencies")